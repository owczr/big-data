{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-04-13T20:48:56.701599Z",
     "end_time": "2023-04-13T20:49:00.057628Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/13 20:48:58 WARN Utils: Your hostname, jakub-G3-3590 resolves to a loopback address: 127.0.1.1; using 192.168.0.102 instead (on interface enp3s0)\n",
      "23/04/13 20:48:58 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/13 20:48:58 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "\n",
    "sc = SparkContext('local')\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Zadanie 3"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from decimal import Decimal\n",
    "\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DateType, DecimalType\n",
    "\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"AccountId\", IntegerType()),\n",
    "    StructField(\"TranDate\", DateType()),\n",
    "    StructField(\"TranAmt\", DecimalType(8, 2))\n",
    "])\n",
    "\n",
    "data = [\n",
    "    ( 1, '2011-01-01', 500),\n",
    "    ( 1, '2011-01-15', 50),\n",
    "    ( 1, '2011-01-22', 250),\n",
    "    ( 1, '2011-01-24', 75),\n",
    "    ( 1, '2011-01-26', 125),\n",
    "    ( 1, '2011-01-28', 175),\n",
    "    ( 2, '2011-01-01', 500),\n",
    "    ( 2, '2011-01-15', 50),\n",
    "    ( 2, '2011-01-22', 25),\n",
    "    ( 2, '2011-01-23', 125),\n",
    "    ( 2, '2011-01-26', 200),\n",
    "    ( 2, '2011-01-29', 250),\n",
    "    ( 3, '2011-01-01', 500),\n",
    "    ( 3, '2011-01-15', 50 ),\n",
    "    ( 3, '2011-01-22', 5000),\n",
    "    ( 3, '2011-01-25', 550),\n",
    "    ( 3, '2011-01-27', 95 ),\n",
    "    ( 3, '2011-01-30', 2500)\n",
    "]\n",
    "\n",
    "data = list(map(lambda x: (x[0], datetime.strptime(x[1], '%Y-%m-%d').date(), Decimal(x[2])), data))\n",
    "df_transactions = spark.createDataFrame(schema=schema, data=data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-13T20:58:36.001055Z",
     "end_time": "2023-04-13T20:58:36.044366Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"RowID\", IntegerType()),\n",
    "    StructField(\"FName\", StringType()),\n",
    "    StructField(\"Salary\", IntegerType())\n",
    "])\n",
    "\n",
    "data = [\n",
    "    (1,'George', 800),\n",
    "    (2,'Sam', 950),\n",
    "    (3,'Diane', 1100),\n",
    "    (4,'Nicholas', 1250),\n",
    "    (5,'Samuel', 1250),\n",
    "    (6,'Patricia', 1300),\n",
    "    (7,'Brian', 1500),\n",
    "    (8,'Thomas', 1600),\n",
    "    (9,'Fran', 2450),\n",
    "    (10,'Debbie', 2850),\n",
    "    (11,'Mark', 2975),\n",
    "    (12,'James', 3000),\n",
    "    (13,'Cynthia', 3000),\n",
    "    (14,'Christopher', 5000)\n",
    "]\n",
    "\n",
    "df_logical = spark.createDataFrame(schema=schema, data=data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-13T20:58:57.152463Z",
     "end_time": "2023-04-13T20:58:57.179208Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+-------+-----------+\n",
      "|AccountId|  TranDate|TranAmt|RunTotalAmt|\n",
      "+---------+----------+-------+-----------+\n",
      "|        1|2011-01-01| 500.00|     500.00|\n",
      "|        1|2011-01-15|  50.00|     550.00|\n",
      "|        1|2011-01-22| 250.00|     800.00|\n",
      "|        1|2011-01-24|  75.00|     875.00|\n",
      "|        1|2011-01-26| 125.00|    1000.00|\n",
      "|        1|2011-01-28| 175.00|    1175.00|\n",
      "|        2|2011-01-01| 500.00|     500.00|\n",
      "|        2|2011-01-15|  50.00|     550.00|\n",
      "|        2|2011-01-22|  25.00|     575.00|\n",
      "|        2|2011-01-23| 125.00|     700.00|\n",
      "|        2|2011-01-26| 200.00|     900.00|\n",
      "|        2|2011-01-29| 250.00|    1150.00|\n",
      "|        3|2011-01-01| 500.00|     500.00|\n",
      "|        3|2011-01-15|  50.00|     550.00|\n",
      "|        3|2011-01-22|5000.00|    5550.00|\n",
      "|        3|2011-01-25| 550.00|    6100.00|\n",
      "|        3|2011-01-27|  95.00|    6195.00|\n",
      "|        3|2011-01-30|2500.00|    8695.00|\n",
      "+---------+----------+-------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.window import Window\n",
    "\n",
    "window_ = Window.partitionBy('AccountId').orderBy(\"TranDate\")\n",
    "df_transactions.withColumn(\"RunTotalAmt\", sum(col(\"TranAmt\")).over(window_)).orderBy([\"AccountId\", \"TranDate\"]).show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-13T21:12:44.763398Z",
     "end_time": "2023-04-13T21:12:44.952362Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+-------+-----------+----------+-----------+-----------+-----------+\n",
      "|AccountId|  TranDate|TranAmt|     RunAvg|RunTranQty|RunSmallAmt|RunLargeAmt|RunTotalAmt|\n",
      "+---------+----------+-------+-----------+----------+-----------+-----------+-----------+\n",
      "|        1|2011-01-01| 500.00| 500.000000|         1|     500.00|     500.00|     500.00|\n",
      "|        1|2011-01-15|  50.00| 275.000000|         2|      50.00|     500.00|     550.00|\n",
      "|        1|2011-01-22| 250.00| 266.666667|         3|      50.00|     500.00|     800.00|\n",
      "|        1|2011-01-24|  75.00| 218.750000|         4|      50.00|     500.00|     875.00|\n",
      "|        1|2011-01-26| 125.00| 200.000000|         5|      50.00|     500.00|    1000.00|\n",
      "|        1|2011-01-28| 175.00| 195.833333|         6|      50.00|     500.00|    1175.00|\n",
      "|        2|2011-01-01| 500.00| 500.000000|         1|     500.00|     500.00|     500.00|\n",
      "|        2|2011-01-15|  50.00| 275.000000|         2|      50.00|     500.00|     550.00|\n",
      "|        2|2011-01-22|  25.00| 191.666667|         3|      25.00|     500.00|     575.00|\n",
      "|        2|2011-01-23| 125.00| 175.000000|         4|      25.00|     500.00|     700.00|\n",
      "|        2|2011-01-26| 200.00| 180.000000|         5|      25.00|     500.00|     900.00|\n",
      "|        2|2011-01-29| 250.00| 191.666667|         6|      25.00|     500.00|    1150.00|\n",
      "|        3|2011-01-01| 500.00| 500.000000|         1|     500.00|     500.00|     500.00|\n",
      "|        3|2011-01-15|  50.00| 275.000000|         2|      50.00|     500.00|     550.00|\n",
      "|        3|2011-01-22|5000.00|1850.000000|         3|      50.00|    5000.00|    5550.00|\n",
      "|        3|2011-01-25| 550.00|1525.000000|         4|      50.00|    5000.00|    6100.00|\n",
      "|        3|2011-01-27|  95.00|1239.000000|         5|      50.00|    5000.00|    6195.00|\n",
      "|        3|2011-01-30|2500.00|1449.166667|         6|      50.00|    5000.00|    8695.00|\n",
      "+---------+----------+-------+-----------+----------+-----------+-----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_transactions \\\n",
    "  .withColumn(\"RunAvg\", avg(col(\"TranAmt\")).over(\n",
    "    Window.partitionBy(\"AccountId\").orderBy(\"TranDate\")\n",
    ")).withColumn(\"RunTranQty\", count(\"*\").over(\n",
    "    Window.partitionBy(\"AccountId\").orderBy(\"TranDate\")\n",
    ")).withColumn(\"RunSmallAmt\", min(col(\"TranAmt\")).over(\n",
    "    Window.partitionBy(\"AccountId\").orderBy(\"TranDate\")\n",
    ")).withColumn(\"RunLargeAmt\", max(col(\"TranAmt\")).over(\n",
    "    Window.partitionBy(\"AccountId\").orderBy(\"TranDate\")\n",
    ")).withColumn(\"RunTotalAmt\", sum(col(\"TranAmt\")).over(\n",
    "    Window.partitionBy(\"AccountId\").orderBy(\"TranDate\")\n",
    ")).orderBy([\"AccountId\", \"TranDate\"]).show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-13T21:23:32.747575Z",
     "end_time": "2023-04-13T21:23:33.118602Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "window_ = Window.partitionBy(\"AccountId\").orderBy(\"TranDate\").rowsBetween(Window.currentRow - 2, Window.currentRow)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-13T21:29:34.876933Z",
     "end_time": "2023-04-13T21:29:34.921861Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+-------+-----------+--------+--------+--------+----------+---+\n",
      "|AccountId|  TranDate|TranAmt|   SlideAvg|SlideQty|SlideMin|SlideMax|SlideTotal| RN|\n",
      "+---------+----------+-------+-----------+--------+--------+--------+----------+---+\n",
      "|        1|2011-01-01| 500.00| 500.000000|       1|  500.00|  500.00|    500.00|  1|\n",
      "|        1|2011-01-15|  50.00| 275.000000|       2|   50.00|  500.00|    550.00|  2|\n",
      "|        1|2011-01-22| 250.00| 266.666667|       3|   50.00|  500.00|    800.00|  3|\n",
      "|        1|2011-01-24|  75.00| 125.000000|       3|   50.00|  250.00|    375.00|  4|\n",
      "|        1|2011-01-26| 125.00| 150.000000|       3|   75.00|  250.00|    450.00|  5|\n",
      "|        1|2011-01-28| 175.00| 125.000000|       3|   75.00|  175.00|    375.00|  6|\n",
      "|        2|2011-01-01| 500.00| 500.000000|       1|  500.00|  500.00|    500.00|  1|\n",
      "|        2|2011-01-15|  50.00| 275.000000|       2|   50.00|  500.00|    550.00|  2|\n",
      "|        2|2011-01-22|  25.00| 191.666667|       3|   25.00|  500.00|    575.00|  3|\n",
      "|        2|2011-01-23| 125.00|  66.666667|       3|   25.00|  125.00|    200.00|  4|\n",
      "|        2|2011-01-26| 200.00| 116.666667|       3|   25.00|  200.00|    350.00|  5|\n",
      "|        2|2011-01-29| 250.00| 191.666667|       3|  125.00|  250.00|    575.00|  6|\n",
      "|        3|2011-01-01| 500.00| 500.000000|       1|  500.00|  500.00|    500.00|  1|\n",
      "|        3|2011-01-15|  50.00| 275.000000|       2|   50.00|  500.00|    550.00|  2|\n",
      "|        3|2011-01-22|5000.00|1850.000000|       3|   50.00| 5000.00|   5550.00|  3|\n",
      "|        3|2011-01-25| 550.00|1866.666667|       3|   50.00| 5000.00|   5600.00|  4|\n",
      "|        3|2011-01-27|  95.00|1881.666667|       3|   95.00| 5000.00|   5645.00|  5|\n",
      "|        3|2011-01-30|2500.00|1048.333333|       3|   95.00| 2500.00|   3145.00|  6|\n",
      "+---------+----------+-------+-----------+--------+--------+--------+----------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_transactions.withColumn(\"SlideAvg\", avg(col(\"TranAmt\")).over(window_ )) \\\n",
    "                .withColumn(\"SlideQty\", count(\"*\").over(window_)) \\\n",
    "                .withColumn(\"SlideMin\", min(col(\"TranAmt\")).over(window_)) \\\n",
    "                .withColumn(\"SlideMax\", max(col(\"TranAmt\")).over(window_)) \\\n",
    "                .withColumn(\"SlideTotal\", sum(col(\"TranAmt\")).over(window_)) \\\n",
    "                .withColumn(\"RN\", row_number().over(\n",
    "                    Window.partitionBy(\"AccountId\").orderBy(\"TranDate\").rowsBetween(Window.unboundedPreceding, Window.currentRow)\n",
    "                    )\n",
    "                ).orderBy([\"AccountId\", \"TranDate\"]).show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-13T21:42:40.696407Z",
     "end_time": "2023-04-13T21:42:40.979405Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/13 22:02:03 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/04/13 22:02:03 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/04/13 22:02:03 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/04/13 22:02:03 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/04/13 22:02:03 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "+-----+-----------+------+---------+----------+\n",
      "|RowID|      FName|Salary|SumByRows|SumByRange|\n",
      "+-----+-----------+------+---------+----------+\n",
      "|    1|     George|   800|      800|       800|\n",
      "|    2|        Sam|   950|     1750|      1750|\n",
      "|    3|      Diane|  1100|     2850|      2850|\n",
      "|    4|   Nicholas|  1250|     4100|      5350|\n",
      "|    5|     Samuel|  1250|     5350|      5350|\n",
      "|    6|   Patricia|  1300|     6650|      6650|\n",
      "|    7|      Brian|  1500|     8150|      8150|\n",
      "|    8|     Thomas|  1600|     9750|      9750|\n",
      "|    9|       Fran|  2450|    12200|     12200|\n",
      "|   10|     Debbie|  2850|    15050|     15050|\n",
      "|   11|       Mark|  2975|    18025|     18025|\n",
      "|   12|      James|  3000|    21025|     24025|\n",
      "|   13|    Cynthia|  3000|    24025|     24025|\n",
      "|   14|Christopher|  5000|    29025|     29025|\n",
      "+-----+-----------+------+---------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "window1 = Window.orderBy(\"Salary\").rowsBetween(Window.unboundedPreceding, Window.currentRow)\n",
    "window2 = Window.orderBy(\"Salary\").rangeBetween(Window.unboundedPreceding, Window.currentRow)\n",
    "\n",
    "df_logical.withColumn(\"SumByRows\", sum(col(\"Salary\")).over(window1)) \\\n",
    "          .withColumn(\"SumByRange\", sum(col(\"Salary\")).over(window2)) \\\n",
    "          .orderBy(\"RowID\") \\\n",
    "          .show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-13T22:02:03.422645Z",
     "end_time": "2023-04-13T22:02:03.662486Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Zadanie 4"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "window_spec = Window.partitionBy(\"RowID\").orderBy(\"Salary\") # .rowsBetween(-2, 0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-13T22:13:04.453264Z",
     "end_time": "2023-04-13T22:13:04.474593Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------+------+----------+---------+---------+\n",
      "|RowID|      FName|Salary|LeadByRows|LagByRows|RowNumber|\n",
      "+-----+-----------+------+----------+---------+---------+\n",
      "|    1|     George|   800|      null|     null|        1|\n",
      "|    2|        Sam|   950|      null|     null|        1|\n",
      "|    3|      Diane|  1100|      null|     null|        1|\n",
      "|    4|   Nicholas|  1250|      null|     null|        1|\n",
      "|    5|     Samuel|  1250|      null|     null|        1|\n",
      "|    6|   Patricia|  1300|      null|     null|        1|\n",
      "|    7|      Brian|  1500|      null|     null|        1|\n",
      "|    8|     Thomas|  1600|      null|     null|        1|\n",
      "|    9|       Fran|  2450|      null|     null|        1|\n",
      "|   10|     Debbie|  2850|      null|     null|        1|\n",
      "|   11|       Mark|  2975|      null|     null|        1|\n",
      "|   12|      James|  3000|      null|     null|        1|\n",
      "|   13|    Cynthia|  3000|      null|     null|        1|\n",
      "|   14|Christopher|  5000|      null|     null|        1|\n",
      "+-----+-----------+------+----------+---------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_logical.withColumn(\"LeadByRows\", lead(col(\"Salary\"), 2).over(window_spec)) \\\n",
    "    .withColumn(\"LagByRows\", lag(col(\"Salary\"), 2).over(window_spec)) \\\n",
    "    .withColumn(\"RowNumber\", row_number().over(window_spec)) \\\n",
    "    .orderBy(\"RowID\") \\\n",
    "    .show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-13T22:13:04.552459Z",
     "end_time": "2023-04-13T22:13:04.724432Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
